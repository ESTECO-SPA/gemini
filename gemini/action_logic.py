import math
from typing import List

import torch

from external import Variational_Generator
from gemini.common import VehicleState, DelayedQueue, VehicleTrajectory, Point2d, TimedVehicleState
from gemini.connector.osi_connector import NearVehicles, GroundTruthInfo


class ActionLogic:

    def act(self, ground_truth_info: GroundTruthInfo, agent_id: int) -> VehicleState:
        pass


class FollowerAgentLogic(ActionLogic):

    def __init__(self, waiting_update: int) -> None:
        self.delayed_queue = DelayedQueue(waiting_update)

    def act(self, ground_truth_info: GroundTruthInfo, agent_id: int) -> VehicleState:
        agent_vehicle = ground_truth_info.get_vehicle_state(agent_id)
        self.delayed_queue.put(agent_vehicle)
        if self.delayed_queue.is_ready():
            return self.delayed_queue.get()


class RepulsingProximityLogic(ActionLogic):

    def __init__(self, radius: float, repulsing_factor: float) -> None:
        super().__init__()
        self.radius = radius
        self.repulsing_factor = repulsing_factor

    def act(self, ground_truth_info, agent_id: int) -> VehicleState:
        agent_vehicle = ground_truth_info.get_vehicle_state(agent_id)
        near_vehicle = NearVehicles(ground_truth_info).get_vehicles_near_to(target_vehicle=agent_vehicle,
                                                                            number_of_vehicles=1)
        nearest_vehicle = near_vehicle[0]
        if agent_vehicle.position_distance(nearest_vehicle) < self.radius:
            repulsing_action = agent_vehicle.position - nearest_vehicle.position
            return agent_vehicle.move_velocity_acceleration(self.repulsing_factor * repulsing_action.unit_vector(), 0.2)


class FollowTrajectoryLogic(ActionLogic):
    def __init__(self, trajectory: VehicleTrajectory) -> None:
        self.trajectory = trajectory

    def act(self, ground_truth_info, agent_id: int) -> VehicleState:
        # import random
        # import time
        # if random.random() > 0.95:
        #     time.sleep(0.05)
        return self.trajectory(ground_truth_info.get_simulation_time())


class VariationalGeneratorLogic(ActionLogic):
    def __init__(self, variational_generator: Variational_Generator, sampling_time: float, visitor: dict) -> None:
        self.sampling_time = sampling_time
        self.time = None
        self.variational_generator = variational_generator
        self.variational_generator.eval()
        # vistor is a dictionary used to store some data. this is useful to understand wht is perceived
        # and generated by the IRL.
        self.visitor = visitor
        self.last_time = None

    def act(self, ground_truth_info: GroundTruthInfo, agent_id: int) -> VehicleState:
        # this if-else statement try to understand the real delta time (self.current_sampling_time) between the actual
        # and  previous model action!
        if not self.last_time:
            self.last_time = ground_truth_info.get_simulation_time()
            self.current_sampling_time = self.sampling_time
        else:
            current_time = ground_truth_info.get_simulation_time()
            self.current_sampling_time = current_time - self.last_time
            self.last_time = current_time
        agent_vehicle = ground_truth_info.get_vehicle_state(agent_id)
        # evaluate the two nearest vehicles within 200mt
        near_vehicles = NearVehicles(ground_truth_info).get_vehicles_near_to(agent_vehicle, 2)
        near_vehicles = [near_vehicle for near_vehicle in near_vehicles if
                         agent_vehicle.position_distance(near_vehicle) < 200]
        # generate the state which is then injected into the IRL model.
        state = self.generate_agent_state(agent_vehicle, near_vehicles)
        self.visitor.setdefault('state', []).append(self.__to_state(state))
        # IRL evaluation
        with torch.no_grad():
            torch_state = self.__to_torch_state(state)
            action, _ = self.variational_generator(torch_state)
        delta_position = action.tolist()[0]
        self.visitor.setdefault('action', []).append(delta_position)
        self.visitor.setdefault('torch_state', []).append(torch_state.numpy()[0])
        self.visitor.setdefault('time', []).append(ground_truth_info.get_simulation_time())
        self.visitor.setdefault('id', []).append([state[0].vehicle_id, state[1].vehicle_id, ])
        delta_position = Point2d(delta_position[0], delta_position[1])
        new_velocity = 1 / self.sampling_time * delta_position
        new_acceleration = Point2d(0, 0)  # we are saying to the simulator that this agent moves at constant speed.
        return VehicleState(agent_vehicle.position, new_velocity, new_acceleration,
                            math.atan2(delta_position.y, delta_position.x))

    @staticmethod
    def generate_agent_state(agent_vehicle, near_vehicles):
        if not near_vehicles:
            state = [VehicleState(position=Point2d(0, 0)), VehicleState(position=Point2d(0, 0)), agent_vehicle]
        elif len(near_vehicles) == 1:
            state = [near_vehicles[0], VehicleState(position=Point2d(0, 0)), agent_vehicle]
        else:
            state = [near_vehicles[0], near_vehicles[1], agent_vehicle]
        return state

    def __to_torch_state(self, vehicles: List[VehicleState]) -> torch.Tensor:
        state = []
        for vehicle in vehicles:
            state.append(vehicle.position.x)
            state.append(vehicle.position.y)
            state.append(vehicle.velocity.x * self.sampling_time)
            state.append(vehicle.velocity.y * self.sampling_time)
            # [REF2] if we give to the irl model the real vehicle acceleration we will see the ziz-zag movement
            state.append(vehicle.acceleration.x * self.sampling_time)  # is it right?
            state.append(vehicle.acceleration.y * self.sampling_time)  # is it right?
            # [REF2] if we "say" to the irl model that all the agents have zero acceleration there is no zig-zag
            # movement. These two options are mutually exclusive
            # state.append(0)
            # state.append(0)
        return torch.Tensor(state).reshape(1, -1)

    @staticmethod
    def __to_state(vehicles: List[VehicleState]):
        state = []
        for vehicle in vehicles:
            state.append(vehicle.position.x)
            state.append(vehicle.position.y)
            state.append(vehicle.velocity.x)
            state.append(vehicle.velocity.y)
            state.append(vehicle.acceleration.x)
            state.append(vehicle.acceleration.y)
        return state


class InertialMovementLogic(ActionLogic):

    def __init__(self, initial_state: TimedVehicleState) -> None:
        self.initial_state = initial_state

    def act(self, ground_truth_info: GroundTruthInfo, agent_id: int) -> VehicleState:
        time = ground_truth_info.get_simulation_time()
        self.initial_state.move(time)
        return self.initial_state.get_state()
